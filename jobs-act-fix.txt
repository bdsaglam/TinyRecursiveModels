# ============================================================================
# VERIFY ENCODER CACHING PERFORMANCE FIX
# Previous issue: O1/E1 ran 100-1000x slower due to encoding entire batch
# Fix: Only encode samples that actually need reset (not the entire batch)
# Expected: ~3-4 sec/it (matching E2's 3.57 it/s)
# ============================================================================

# O1-fix: Original mode baseline - verify standard encoder now runs fast
# Previous: 422 sec/it → Expected: ~3-4 sec/it
[!] torchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain_encoder_original.py --config-name cfg_pretrain_encoder_original_arc_agi_1 load_pretrained_decoder=/home/baris/repos/trm/checkpoints/Arc1concept-aug-1000-ACT-torch/pretrain_att_arc1concept_4/step_518071 max_train_groups=32 max_eval_groups=32 epochs=5000 eval_interval=5000 +project_name="mmi-714-act-fix" +run_name="O1_fix_standard"

# E1-fix: Original mode + Hybrid Standard - verify hybrid_standard now runs fast
# Previous: 39 sec/it → Expected: ~3-4 sec/it
[!] torchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain_encoder_original.py --config-name cfg_pretrain_encoder_original_arc_agi_1 load_pretrained_decoder=/home/baris/repos/trm/checkpoints/Arc1concept-aug-1000-ACT-torch/pretrain_att_arc1concept_4/step_518071 arch.encoder_type=hybrid_standard arch.encoder_num_layers=4 arch.encoder_norm_style=pre arch.encoder_set_layers=2 max_train_groups=32 max_eval_groups=32 global_batch_size=128 epochs=5000 eval_interval=5000 +project_name="mmi-714-act-fix" +run_name="E1_fix_hybrid_std"

