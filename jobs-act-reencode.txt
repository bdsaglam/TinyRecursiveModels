# ============================================================================
# APPROACH 4 VERIFICATION: ACT TRM with Re-encoding (No Caching)
#
# This tests the new implementation that re-encodes the full batch every step
# instead of caching encoder outputs. This should provide:
# - Full encoder gradient coverage (100% like online mode)
# - Dynamic halting benefits (adaptive compute)
# - Expected accuracy: ~96-97% (matching online mode baseline)
# ============================================================================

# Baseline: Online mode for comparison
# Expected: ~96.7% train accuracy, ~3.5 it/s
# This is the reference we're trying to match
[x] torchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain_encoder.py --config-name cfg_pretrain_encoder_arc_agi_1 load_pretrained_decoder=/home/baris/repos/trm/checkpoints/Arc1concept-aug-1000-ACT-torch/pretrain_att_arc1concept_4/step_518071 max_train_groups=32 max_eval_groups=32 epochs=5000 eval_interval=5000 +project_name=\"mmi-714-act-reencode\" +run_name=\"L1_online_baseline\"

# Approach 4: Original mode with re-encoding (standard encoder)
# Expected: ~96-97% train accuracy (matching baseline), adaptive steps
# This should achieve similar accuracy to online mode with dynamic halting
[x] torchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain_encoder_original.py --config-name cfg_pretrain_encoder_original_arc_agi_1 load_pretrained_decoder=/home/baris/repos/trm/checkpoints/Arc1concept-aug-1000-ACT-torch/pretrain_att_arc1concept_4/step_518071 max_train_groups=32 max_eval_groups=32 epochs=5000 eval_interval=5000 +project_name="mmi-714-act-reencode" +run_name="O1_reencode_std"

# Approach 4: Original mode with re-encoding (hybrid_standard encoder)
# Expected: ~96-97% train accuracy, adaptive steps
# Tests if re-encoding works with different encoder architectures
[!] torchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain_encoder_original.py --config-name cfg_pretrain_encoder_original_arc_agi_1 load_pretrained_decoder=/home/baris/repos/trm/checkpoints/Arc1concept-aug-1000-ACT-torch/pretrain_att_arc1concept_4/step_518071 arch.encoder_type=hybrid_standard arch.encoder_num_layers=4 arch.encoder_norm_style=pre arch.encoder_set_layers=2 max_train_groups=32 max_eval_groups=32 global_batch_size=128 epochs=5000 eval_interval=5000 +project_name="mmi-714-act-reencode" +run_name="O2_reencode_hybrid"

# Success criteria:
# 1. O1/O2 achieve train_accuracy >= 0.90 (ideally ~0.96-0.97 matching L1)
# 2. O1/O2 show adaptive steps (some samples halt early, some continue)
# 3. Encoder gradients are non-zero (grad/encoder_norm > 0)
# 4. Training speed is acceptable (~3-5 sec/it)
